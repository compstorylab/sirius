{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare feature importance values from random forest prediction to the components in the backbone network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 50\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import setup\n",
    "from data_processing import classify_features, load_data\n",
    "from mutual_info import calc_mi\n",
    "from network import output_graph_json, output_pairs_json, threshold_using_backbone_method, get_components\n",
    "from visualization import draw_graph, viz, show_edge_thinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select our target directory and set our parameters:\n",
    "Optional: You can set up parameters from an outside file using `args = setup.arg_setup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_dir = 'example_housing' #'example_housing' #'example_groceries' #'example_icu' #'example_data'\n",
    "args = {'charter': 'Plotly',\n",
    "        'input_file': f'../{target_dir}/data.csv',\n",
    "        'output_dir': f'../{target_dir}/output',\n",
    "        'sample_n': None, #None, #100 (recommended for testing example_icu or other large data sets)\n",
    "        'output_json': True,\n",
    "        'output_charts': False,\n",
    "        'feature_of_interest': 'YearBuilt' #'Neighborhood' #'whole_milk' #'diabetes_mellitus' #'Continuous_Trinary_Normal'\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Sirius algorithm to get sparsified mutual information graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = load_data(Path(args['input_file']), sample_n=args['sample_n'])\n",
    "print(f'There are {df.shape[0]} records and {df.shape[1]} features in {args[\"input_file\"]}')\n",
    "# Classify features as discrete or continuous\n",
    "feature_info = classify_features(df)\n",
    "# Calculate mutual information for each pair of features\n",
    "edges = calc_mi(df, feature_info).sort_values(by='v', ascending=False).reset_index(drop=True)\n",
    "# Sparsify the mutual information graph using the backbone method\n",
    "thresheld = threshold_using_backbone_method(edges, debug=True)\n",
    "# Get the component list from the sparsified network\n",
    "components = get_components(thresheld)\n",
    "# Visualize the network graph\n",
    "draw_graph(thresheld, f'Filtered Feature Graph: Reduced to {thresheld.shape[0]} Connections', display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find importance values of other features for prediction of one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a discrete variable to predict (with the specific response being predicted)\n",
    "feature_of_interest = 'Neighborhood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or choose a continuous feature to predict:\n",
    "#feature_of_interest = 'YearBuilt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_of_interest in list(feature_info[feature_info['type']=='d'].index):\n",
    "    print(f\"Because this is a discrete variable, you must set a response of interest from one of the following:{list(df[feature_of_interest].unique())}\")\n",
    "    response_of_interest=\"OldTown\"\n",
    "    predict = str(feature_of_interest+\"_\"+response_of_interest)\n",
    "else:\n",
    "    predict = feature_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of discrete features from the Sirius type classifier\n",
    "d_features = list(feature_info[feature_info['type']=='d'].index)\n",
    "# Create a subset dataframe of only continuous values\n",
    "d_df = df.filter(d_features)\n",
    "try: d_df.drop(columns=[feature_of_interest], inplace=True)\n",
    "except: print(f'{feature_of_interest} not included in discrete subset dataframe')\n",
    "print(d_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map discrete features to binary values using one-hot encoding\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(d_df.fillna('None').values)\n",
    "encoded = enc.transform(d_df.fillna('None').values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded array back into a dataframe\n",
    "e_df = pd.DataFrame(encoded, columns=enc.get_feature_names(d_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a list of continuous features from the Sirius type classifier\n",
    "c_features = list(feature_info[feature_info['type']=='c'].index)\n",
    "# Create a subset dataframe of only continuous values\n",
    "c_df = df.filter(c_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the encoded discrete data frame with the continuous data frame\n",
    "merged_df = e_df.merge(c_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull array of values to predict and create matrix of known values\n",
    "y = merged_df[predict].values\n",
    "try: known_df = merged_df.drop(columns=[predict])\n",
    "except: known_df = merged_df\n",
    "X = known_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest regressor on all the known features\n",
    "regressor = RandomForestRegressor(n_estimators=known_df.shape[1], random_state=0)\n",
    "# Fit the random forest regressor to the data\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predict the feature of interest value\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Print the prediction error metadata\n",
    "print('Mean absolute error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean squared error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root mean squared error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a data frame of the feature importances for the prediction task\n",
    "importances = pd.DataFrame(sorted(zip(map(lambda x: round(x, 4), regressor.feature_importances_), known_df.columns), \n",
    "             reverse=True), columns=['importance','feature_encoded'])\n",
    "# If the feature was encoded, map the feature importance value for that feature to the highest importance value for all encoded fields (this is just to get a rough estimate)\n",
    "importances['feature']=[f if f in df.columns else f.split('_')[0] for f in importances['feature_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rankings data frame which includes mutual information scores for all features related to the feature of interest\n",
    "rankings = edges[(edges['x']==feature_of_interest) | (edges['y']==feature_of_interest)].rename(columns={'v':'mi_score'}).reset_index(drop=True)\n",
    "rankings['mi_ranking']=[i+1 for i in rankings.index] # Feature importance rankings start at 1 instead of 0\n",
    "rankings['feature']=[x if x!=feature_of_interest else y for x,y in zip(rankings['x'],rankings['y'])]\n",
    "rankings.drop(columns=['x','y'],inplace=True)\n",
    "rankings['importance_score']=[list(importances[importances.feature==f].importance)[0] if f in list(importances.feature) else None for f in rankings['feature']]\n",
    "rankings['importance_ranking']=[list(importances.feature).index(f) if f in list(importances.feature) else None for f in rankings['feature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a visualization of any feature vs. the feature for which a value is being predicted, and show the mutual information and importance scores and rankings\n",
    "def makeviz(known,predicting):\n",
    "    print(f'Creating visualization of known value \"{known}\" vs. prediction feature \"{predicting}\"')\n",
    "    viz(known, predicting, df, feature_info, charter=args['charter'],display=True, resolution=100)\n",
    "    print(f'Importance score for {known} and {predicting}: {list(rankings[rankings.feature==known].importance_score)[0]}')\n",
    "    print(f'Mutual information score for {known} and {predicting}: {list(rankings[rankings.feature==known].mi_score)[0]}')\n",
    "    print(f'Importance rank for {known} and {predicting}: {list(rankings[rankings.feature==known].importance_ranking)[0]}')\n",
    "    print(f'Mutual information rank for {known} and {predicting}: {list(rankings[rankings.feature==known].mi_ranking)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create pairwise visualizations of the top 5 most important features for prediction (these may contain duplicates due to one-hot encoding step)\n",
    "for i in list(importances['feature'])[:5]:\n",
    "    makeviz(i,feature_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the spearman rank correlation between mutual information and feature importance\n",
    "spearman = stats.spearmanr(rankings['mi_score'],rankings['importance_score'])\n",
    "correlation = spearman.correlation\n",
    "p_val = spearman.pvalue\n",
    "spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of the relationship between mutual information and importance for features in the prediction of the feature of interest\n",
    "fig = px.scatter(rankings, title=f\"Mutual Information vs. Importance Ranking of Features for Prediction of <b>'{predict.replace('_',': ')}</b>'<br>Spearman Correlation: {np.round(correlation,3)}, p-Value: {np.format_float_scientific(p_val,precision=1)}\", x='mi_ranking',y='importance_ranking',hover_name='feature',height=800, trendline=\"ols\",template='plotly_white')\n",
    "fig.update_xaxes(range=[rankings['mi_ranking'].max()+5, rankings['mi_ranking'].min()-5])\n",
    "fig.update_yaxes(range=[rankings['importance_ranking'].max()+5, rankings['importance_ranking'].min()-5])\n",
    "fig.update_traces(marker=dict(size=15))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}